{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1627d6d2",
   "metadata": {},
   "source": [
    "# TEXT Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d19529f",
   "metadata": {},
   "source": [
    "# Label text data without labeled training set\n",
    "\n",
    "If you don't have a labeled dataset, there are still several approaches you can take to categorize paragraphs into categories A, B, and C using BERT. Here are some strategies:\n",
    "\n",
    "### 1. **Manual Labeling (Creating a Labeled Dataset)**\n",
    "   - **Manually Label a Small Dataset**: You can start by manually labeling a small set of paragraphs. This can be time-consuming but provides a solid foundation for training a model. Even a small labeled dataset can be useful for fine-tuning BERT.\n",
    "   - **Active Learning**: In this approach, you can iteratively label the most uncertain or challenging samples. The model can suggest which paragraphs to label next, focusing on those where the model is most unsure.\n",
    "\n",
    "### 2. **Weak Supervision**\n",
    "   - **Rule-Based Labeling**: Create heuristic rules based on the definitions of categories A, B, and C. For example, you might look for specific keywords or phrases in paragraphs that are indicative of each category. These rules can be used to generate noisy labels, which can then be used to train BERT.\n",
    "   - **Distant Supervision**: Use external data sources where labels might be indirectly available (e.g., using labels from related tasks or datasets). You can align these labels with your task.\n",
    "\n",
    "### 3. **Semi-Supervised Learning**\n",
    "   - **Self-Training**: First, label a small dataset manually. Train BERT on this small dataset and then use the model to predict labels for the unlabeled data. You can then iteratively retrain the model using a combination of labeled and pseudo-labeled data.\n",
    "   - **Label Propagation**: Use techniques like label spreading, where labels from a small labeled set are propagated to the unlabeled data based on feature similarity.\n",
    "\n",
    "### 4. **Zero-Shot Learning**\n",
    "   - **Zero-Shot Classification with Pre-Trained Models**: Use a model like BART, GPT, or RoBERTa that can handle zero-shot classification. You can prompt these models with definitions of categories A, B, and C, and ask them to classify paragraphs accordingly without fine-tuning.\n",
    "   - Example:\n",
    "     ```python\n",
    "     from transformers import pipeline\n",
    "     \n",
    "     classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "     \n",
    "     paragraphs = [\"Paragraph text 1\", \"Paragraph text 2\", \"Paragraph text 3\"]\n",
    "     labels = [\"Category A\", \"Category B\", \"Category C\"]\n",
    "     \n",
    "     for paragraph in paragraphs:\n",
    "         result = classifier(paragraph, labels)\n",
    "         print(f\"Paragraph: {paragraph}\\nPredicted Category: {result['labels'][0]}\\n\")\n",
    "     ```\n",
    "   - **Pros**: No need for labeled data.\n",
    "   - **Cons**: Performance may not be as strong as with fine-tuning on a labeled dataset.\n",
    "\n",
    "### 5. **Unsupervised Learning**\n",
    "   - **Clustering**: Use clustering algorithms like K-means, DBSCAN, or hierarchical clustering to group similar paragraphs together. After clustering, you can manually label each cluster with category A, B, or C.\n",
    "   - **Topic Modeling**: Apply topic modeling techniques (like Latent Dirichlet Allocation, LDA) to identify themes in the paragraphs. These themes can be mapped to categories A, B, and C.\n",
    "\n",
    "### 6. **Few-Shot Learning**\n",
    "   - **Few-Shot Learning Models**: Use models like GPT-3, which can be prompted with a few examples of each category (A, B, and C) and can classify new paragraphs based on these few examples. This approach doesnâ€™t require a large labeled dataset.\n",
    "   - **Prompt Engineering**: Create prompts that guide the model to understand the categories. For example:\n",
    "     ```python\n",
    "     paragraph = \"This paragraph is about...\"\n",
    "     prompt = f\"Which category does the following paragraph belong to? Paragraph: {paragraph} \\n\\nCategories: A: [Definition], B: [Definition], C: [Definition]\"\n",
    "     ```\n",
    "\n",
    "### Summary:\n",
    "- **Manual Labeling** is the most reliable but time-intensive.\n",
    "- **Weak Supervision** and **Semi-Supervised Learning** can help bootstrap a labeled dataset from heuristic rules or small labeled sets.\n",
    "- **Zero-Shot Learning** allows categorization without any labeled data but may require careful prompt design.\n",
    "- **Unsupervised Learning** can provide insights into the structure of your data, which can then be mapped to categories.\n",
    "- **Few-Shot Learning** leverages powerful models like GPT-3 to classify paragraphs with minimal labeled examples.\n",
    "\n",
    "Each of these methods has trade-offs in terms of accuracy, effort, and applicability, so the choice depends on your specific use case and available resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1fb6e",
   "metadata": {},
   "source": [
    "Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26731d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define your categories with their definitions\n",
    "labels = [\"Technology and Innovation\", \"Health and Wellness\", \"Financial and Economic\"]\n",
    "\n",
    "# Example paragraphs to classify\n",
    "paragraphs = [\n",
    "    \"This new AI model is revolutionizing the tech industry by improving the accuracy of predictions.\",\n",
    "    \"Eating a balanced diet and exercising regularly are key to maintaining good health.\",\n",
    "    \"The stock market experienced a significant drop due to economic instability.\"\n",
    "]\n",
    "\n",
    "# Perform zero-shot classification for each paragraph\n",
    "for paragraph in paragraphs:\n",
    "    result = classifier(paragraph, labels)\n",
    "    print(f\"Paragraph: {paragraph}\")\n",
    "    print(f\"Predicted Category: {result['labels'][0]} with confidence {result['scores'][0]:.4f}\")\n",
    "    print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d254e5",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "Classifier Initialization: We use the pipeline function from the transformers library, specifying the task as \"zero-shot-classification\" and using the \"facebook/bart-large-mnli\" model.\n",
    "Labels: We provide the model with the categories we want to classify the paragraphs into. These categories are described as simple phrases that reflect the content of each category.\n",
    "Prediction: For each paragraph, the model predicts which category it belongs to, along with a confidence score. The category with the highest confidence score is the one the model assigns to the paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850645a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent running the code: 0.0393 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# The code block you want to measure\n",
    "# (Replace this with your actual code)\n",
    "for i in range(1000000):\n",
    "    pass  # Example loop\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"Time spent running the code: {elapsed_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada3ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
